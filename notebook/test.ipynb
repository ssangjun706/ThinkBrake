{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a47f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    model_id = \"microsoft/phi-4-reasoning\"\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            trust_remote_code=True,\n",
    "            dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "        return tokenizer, model\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load any Phi-4 model. Last error: {e}\")\n",
    "\n",
    "\n",
    "def solve(problem: str):\n",
    "    tokenizer, model = load_model()\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are Phi, a language model trained by Microsoft to help users. Your role as an assistant involves thoroughly exploring questions through a systematic thinking process before providing the final precise and accurate solutions. This requires engaging in a comprehensive cycle of analysis, summarizing, exploration, reassessment, reflection, backtracing, and iteration to develop well-considered thinking process. Please structure your response into two main sections: Thought and Solution using the specified format: <think> {Thought section} </think> {Solution section}. In the Thought section, detail your reasoning process in steps. Each step should include detailed considerations such as analysing questions, summarizing relevant findings, brainstorming new ideas, verifying the accuracy of the current steps, refining any errors, and revisiting previous steps. In the Solution section, based on various attempts, explorations, and reflections from the Thought section, systematically present the final solution that you deem correct. The Solution section should be logical, accurate, and concise and detail necessary steps needed to reach the conclusion. Now, try to solve the following question through the above guidelines:\"},\n",
    "        {\"role\": \"user\", \"content\": problem},\n",
    "    ]\n",
    "    inputs = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "\n",
    "    gen_ids = model.generate(\n",
    "        inputs.to(model.device),\n",
    "        max_new_tokens=2048,\n",
    "        temperature=0.8,\n",
    "        top_p=0.95,\n",
    "        top_k=50,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    output_text = tokenizer.decode(\n",
    "        gen_ids[0], skip_special_tokens=True\n",
    "    )\n",
    "    print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae343d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = (\n",
    "        \"A bat and a ball cost $1.10 in total, and the bat costs $1.00 more than the ball. \"\n",
    "        \"How much does the ball cost?\"\n",
    "    )\n",
    "solve(problem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ThinkBrake (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
